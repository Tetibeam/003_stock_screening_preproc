{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd607b5",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe0f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "🔁 autoreload 有効化完了\n"
     ]
    }
   ],
   "source": [
    "# --- Notebook初期設定 ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import src.config as cfg\n",
    "import src.data_loader as dl\n",
    "import src.cleaning_utils as cu\n",
    "print(\"🔁 autoreload 有効化完了\")\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79cbfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'stock_screening',\n",
       " 'data_path': {'raw': './data/raw',\n",
       "  'interim': './data/interim',\n",
       "  'processed': './data/processed'},\n",
       " 'files': {'raw': ['fy-balance-sheet.csv',\n",
       "   'fy-cash-flow-statement.csv',\n",
       "   'fy-profit-and-loss.csv',\n",
       "   'fy-stock-dividend.csv'],\n",
       "  'reference': ['CodeData.csv'],\n",
       "  'interim': None,\n",
       "  'processed': None},\n",
       " 'years': [2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2015,\n",
       "  2016,\n",
       "  2017,\n",
       "  2018,\n",
       "  2019,\n",
       "  2020,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2024,\n",
       "  2025],\n",
       " 'na_values': [''],\n",
       " 'output': {'base_path': './output'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 設定読み込み\n",
    "settings = cfg.load_settings(\"setting.yaml\")\n",
    "display(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6ff0d",
   "metadata": {},
   "source": [
    "## 本ファイルの説明\n",
    "データが最低限の品質基準を満たしているかを網羅的に確認します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdaa036",
   "metadata": {},
   "source": [
    "### データのロードの確認\n",
    "\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "ファイルの重複や欠損はなく、正しくロードされました。\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ファイル毎にデータをロードします\n",
      "\n",
      "エラーなくロードできているようです。次に欠けてるファイルがないか確認します\n",
      "\n",
      "欠けているファイルはないようです、次に重複ファイルがないか確認します\n",
      "✅ 重複データフレームはありません。\n",
      "\n",
      "重複しているファイルはないようです。\n",
      "データロードの確認を終了します。\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"ファイル毎にデータをロードします\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"],[\"\"]\n",
    ")\n",
    "#display(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"エラーなくロードできているようです。次に欠けてるファイルがないか確認します\")\n",
    "for (filename,year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    if df.empty:\n",
    "        print(file,year,\"データフレームが空です\")\n",
    "    else:\n",
    "        #print(\"OK\")\n",
    "        continue\n",
    "\n",
    "print(\"\")\n",
    "print(\"欠けているファイルはないようです、次に重複ファイルがないか確認します\")\n",
    "def df_hash(df, ignore_order=False):\n",
    "    data_only = df.copy().fillna(\"\").astype(str)\n",
    "    if ignore_order:\n",
    "        # 行順も無視（全列ソートしてから比較）\n",
    "        data_only = data_only.sort_values(by=data_only.columns.tolist()).reset_index(drop=True)\n",
    "    # 列名を無視して内容だけでハッシュを生成\n",
    "    h = hashlib.md5(pd.util.hash_pandas_object(data_only, index=True).values)\n",
    "    return h.hexdigest()\n",
    "hash_map = defaultdict(list)\n",
    "for (fname, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    h = df_hash(df, ignore_order=False)  # ←行順を無視したいなら True に\n",
    "    hash_map[h].append((fname, year))\n",
    "duplicates = {h: keys for h, keys in hash_map.items() if len(keys) > 1}\n",
    "if duplicates:\n",
    "    print(\"🔍 同じ内容のデータフレーム（ヘッダー無視）が見つかりました：\\n\")\n",
    "    for h, key_group in duplicates.items():\n",
    "        print(f\"ハッシュ: {h}\")\n",
    "        for fname, year in key_group:\n",
    "            print(f\"  - {fname}（{year}）\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"✅ 重複データフレームはありません。\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"重複しているファイルはないようです。\")\n",
    "print(\"\")\n",
    "print(\"データロードの確認を終了します。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59706c4a",
   "metadata": {},
   "source": [
    "### 欠損値表現の確認と処理\n",
    "\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の表現確認\n",
    "print(\"\")\n",
    "print(\"ファイル毎にデータを取得します\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"],[\"\"]\n",
    ")\n",
    "#display(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ファイルごとに各文字列の個数をカウントします\")\n",
    "#\"nan\", \"na\", \"n/a\", \"null\", \"-\", \"--\", \"none\", \"0\",\" \",\"\"\n",
    "\n",
    "df_placeholder_counts = pd.DataFrame(\n",
    "    columns=[\"col\",\"nan\",\"na\",\"n/a\",\"-\",\"--\",\"none\",\"0\",\"space\",\"\",\"alphabet\"],\n",
    ")\n",
    "display(df_placeholder_counts)\n",
    "for (filename,year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    counts = []\n",
    "    for col in df:\n",
    "        ser = df[col].fillna(\"\")\n",
    "        ser_str = ser.astype(str)\n",
    "        #display(ser_str)\n",
    "        counts.append(\n",
    "            (col,\n",
    "            (ser_str == 'nan').sum(),\n",
    "            (ser_str == 'na').sum(),\n",
    "            (ser_str == 'n/a').sum(),\n",
    "            (ser_str == '-').sum(),\n",
    "            (ser_str == '--').sum(),\n",
    "            (ser_str == 'none').sum(),\n",
    "            (ser_str == '0').sum(),\n",
    "            (ser_str == ' ').sum(),\n",
    "            (ser_str == '').sum(),\n",
    "            ser_str.str.contains('[A-Za-z]', na=False).sum())\n",
    "        )\n",
    "        df_placeholder_counts.loc[df_placeholder_counts.index.max()+1] = counts\n",
    "        display(df_placeholder_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868eb6bf",
   "metadata": {},
   "source": [
    "### データ型の整合性確認\n",
    "\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587ff61",
   "metadata": {},
   "source": [
    "### 初期品質の概要確認\n",
    "\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 財務データ 結合前\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_rows', 60)\n",
    "\n",
    "def get_file_info(df_datas_by_all_files):\n",
    "    df_file_info = pd.DataFrame(columns=[\"file\",\"year\",\"code_counts\",\"year_counts\",\"column_counts\"])\n",
    "    for file, year in df_datas_by_all_files.keys():\n",
    "        df = df_datas_by_all_files[(file,year)]\n",
    "        # len(df_file_info)を次の新しい行のインデックスとして明示的に指定します。\n",
    "        df_file_info.loc[len(df_file_info)] = [\n",
    "            file, year, df[\"コード\"].nunique(), df[\"年度\"].nunique(),df.columns.nunique()\n",
    "        ]\n",
    "    return df_file_info\n",
    "\n",
    "print(\"\")\n",
    "print(\"ファイル毎にデータを取得します\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"],[\"-\",\"\",\"0\"]\n",
    ")\n",
    "#display(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"企業コード数、エンドの数、列数をファイルごとにまとめます。\")\n",
    "df_file_info = get_file_info(df_DATAs_BY_ALL_FILEs)\n",
    "#display(df_file_info)\n",
    "\n",
    "print(\"\")\n",
    "print(\"各ファイルの年推移を可視化します。\")\n",
    "\"\"\"fig = px.line(df_file_info,x=\"year\",y=\"code_counts\",color=\"file\")\n",
    "fig.show()\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"year_counts\",color=\"file\")\n",
    "fig.show()\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"column_counts\",color=\"file\")\n",
    "fig.show()\"\"\"\n",
    "\n",
    "print(\"\")\n",
    "print(\"列数はOKです\")\n",
    "print(\"最新年のファイルに登録されている年度を表示します。\")\n",
    "df = df_DATAs_BY_ALL_FILEs[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[\"年度\"].unique())\n",
    "\n",
    "print(\"\")\n",
    "print(\"最新年のファイルに過去のデータがあります。\")\n",
    "print(\"最新年に登録されている過去の年度と過去のデータが同じか確認します\")\n",
    "print(\"まずは、年度を限定して、コードの一覧を見ます\")\n",
    "#display(df[df[\"年度\"]==\"2024/12\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"コードを限定し同じかどうか調べます。\")\n",
    "df = df_DATAs_BY_ALL_FILEs[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[df[\"コード\"]==\"130A\"])\n",
    "df = df_DATAs_BY_ALL_FILEs[(settings[\"files\"][\"raw\"][0],2024)]\n",
    "#display(df[df[\"コード\"]==\"130A\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"違っています。これは更新データと思われます。\")\n",
    "print(\"最新年度にある過去のデータを取得し、過去のデータを更新します\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.update_duplicated(df_DATAs_BY_ALL_FILEs, 2025)\n",
    "#display(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"正しく処理が行われ、最新年に登録されている過去の年度と過去のデータが同じか確認します。\")\n",
    "df = df_DATAs_BY_ALL_FILEs[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[df[\"コード\"]==\"130A\"])\n",
    "df = df_DATAs_BY_ALL_FILEs[(settings[\"files\"][\"raw\"][0],2024)]\n",
    "#display(df[df[\"コード\"]==\"130A\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"最後に最新年度にある過去のデータを消去します。\")\n",
    "cutoff_date = pd.to_datetime(\"2025-01-01\")\n",
    "for file, year in df_DATAs_BY_ALL_FILEs.keys():\n",
    "    if year == 2025:\n",
    "        df = df_DATAs_BY_ALL_FILEs[(file,year)]\n",
    "        df = df[df[\"年度\"] >= cutoff_date]\n",
    "        df_DATAs_BY_ALL_FILEs[(file,year)] = df\n",
    "print(\"\")\n",
    "print(\"各ファイルの年推移をもう一度可視化し、改善していることを確かめます。\") \n",
    "df_file_info_after = get_file_info(df_DATAs_BY_ALL_FILEs)\n",
    "df_file_info_after[\"区分\"] = \"処理後\"\n",
    "df_file_info_after = df_file_info_after.set_index([\"file\", \"year\"]).sort_index()\n",
    "df_file_info[\"区分\"] = \"処理前\"\n",
    "df_file_info = df_file_info.set_index([\"file\", \"year\"]).sort_index()\n",
    "df_compare = pd.concat([df_file_info,df_file_info_after]).sort_index().reset_index()\n",
    "#display(df_compare)\n",
    "fig = px.line(df_compare,x=\"year\",y=\"code_counts\",color=\"区分\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 財務データ ファイルごとの結合\n",
    "df_DATAs_BY_FILEs = dl.load_yearly_data(settings[\"data_path\"], settings[\"years\"], settings[\"files\"],)\n",
    "target_file = settings[\"files\"][0]\n",
    "display(df_DATAs_BY_FILEs[target_file][df_DATAs_BY_FILEs[target_file][\"コード\"]==\"130A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 財務データ　全結合\n",
    "df_ALL_DATAs = dl.merge_all_data(df_DATAs_BY_FILEs)\n",
    "print(df_ALL_DATAs.shape)\n",
    "#display(df_ALL_DATAs)\n",
    "display(df_ALL_DATAs[\"コード\"].unique())\n",
    "display(df_ALL_DATAs[\"年度\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6804e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上場企業の情報\n",
    "df = dl.load_code_list_info(settings[\"data_path\"], settings[\"files_reference\"][0])\n",
    "print(settings[\"files_reference\"][0], df.shape)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeeca61",
   "metadata": {},
   "source": [
    "### データ型の整合性チェック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc595948",
   "metadata": {},
   "source": [
    "### 初期品質の概要把握"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
