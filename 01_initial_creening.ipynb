{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd607b5",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe0f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 autoreload 有効化完了\n"
     ]
    }
   ],
   "source": [
    "# --- Notebook初期設定 ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import src.config as cfg\n",
    "import src.data_loader as dl\n",
    "import src.data_cleaning_utils as cu\n",
    "print(\"🔁 autoreload 有効化完了\")\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79cbfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'stock_screening',\n",
       " 'data_path': {'raw': './data/raw',\n",
       "  'interim': './data/interim',\n",
       "  'processed': './data/processed',\n",
       "  'reference': './data/reference'},\n",
       " 'files': {'raw': ['fy-balance-sheet.csv',\n",
       "   'fy-cash-flow-statement.csv',\n",
       "   'fy-profit-and-loss.csv',\n",
       "   'fy-stock-dividend.csv'],\n",
       "  'reference': 'CodeData.csv',\n",
       "  'interim': None,\n",
       "  'processed': None},\n",
       " 'years': [2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2015,\n",
       "  2016,\n",
       "  2017,\n",
       "  2018,\n",
       "  2019,\n",
       "  2020,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2024,\n",
       "  2025],\n",
       " 'na_values': [''],\n",
       " 'output': {'base_path': './output'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 設定読み込み\n",
    "settings = cfg.load_settings(\"setting.yaml\")\n",
    "display(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6ff0d",
   "metadata": {},
   "source": [
    "## 本ファイルの説明\n",
    "データが最低限の品質基準を満たしているかを網羅的に確認し、ファイルロードからクリーニングまでのプロセスを決定します。\n",
    "\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdaa036",
   "metadata": {},
   "source": [
    "### データのロードの確認\n",
    "ファイル重複やファイル欠損、破壊がないかを確かめ、プロセスを確定します。\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "ファイルの重複や欠損はなく、正しくロードされました。  \n",
    "修正処理は不要です。\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"ファイル毎にデータをロードします\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"]\n",
    ")\n",
    "display(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"次に欠けてるファイルがないか確認します\")\n",
    "def chk_file_missing(df_DATAs_BY_ALL_FILEs):\n",
    "    flg = True\n",
    "    for (filename,year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "        if df.empty:\n",
    "            print(\"❌ \".filename,year,\"データフレームが空です\")\n",
    "            flg = False\n",
    "    if flg:\n",
    "        print(\"✅ ファイル欠損はありません。\")\n",
    "chk_file_missing(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"重複ファイルがないか確認します\")\n",
    "def df_hash(df, ignore_order=False):\n",
    "    data_only = df.copy().fillna(\"\").astype(str)\n",
    "    if ignore_order:\n",
    "        # 行順も無視（全列ソートしてから比較）\n",
    "        data_only = data_only.sort_values(by=data_only.columns.tolist()).reset_index(drop=True)\n",
    "    # 列名を無視して内容だけでハッシュを生成\n",
    "    h = hashlib.md5(pd.util.hash_pandas_object(data_only, index=True).values)\n",
    "    return h.hexdigest()\n",
    "hash_map = defaultdict(list)\n",
    "for (fname, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    h = df_hash(df, ignore_order=False)  # ←行順を無視したいなら True に\n",
    "    hash_map[h].append((fname, year))\n",
    "duplicates = {h: keys for h, keys in hash_map.items() if len(keys) > 1}\n",
    "if duplicates:\n",
    "    print(\"🔍 同じ内容のデータフレーム（ヘッダー無視）が見つかりました：\\n\")\n",
    "    for h, key_group in duplicates.items():\n",
    "        print(f\"ハッシュ: {h}\")\n",
    "        for fname, year in key_group:\n",
    "            print(f\"  - {fname}（{year}）\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"✅ 重複データフレームはありません。\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"データロードの確認を終了します。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59706c4a",
   "metadata": {},
   "source": [
    "### 欠損値表現の確認と処理\n",
    "欠損値の表現を確認し、修正プロセスを決定します。\n",
    "\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "\"-\"が欠損値として使われています。  \n",
    "これはsetting.yamlのnan_valuesに登録し欠損値として読み込みます。  \n",
    "  \n",
    "また、ゼロも使われています。  \n",
    "ゼロは値として残し、必要に応じてfeatures_generatorで再計算し更新します。\n",
    "\n",
    "以下がゼロが使われている項目です。  \n",
    "{'fy-balance-sheet.csv': ['BPS', '短期借入金', '総資産', '自己資本比率', '長期借入金']  \n",
    "'fy-cash-flow-statement.csv': ['営業CF', '営業CFマージン', '投資CF', '現金同等物', '設備投資', '財務CF']  \n",
    "'fy-profit-and-loss.csv': ['EPS', 'ROA', 'ROE', '営業利益', '売上高', '純利益', '経常利益'],  \n",
    "'fy-stock-dividend.csv': ['一株配当', '剰余金の配当', '純資産配当率', '総還元性向', '自社株買い', '配当性向']}\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値の表現確認\n",
    "print(\"\")\n",
    "print(\"ファイル毎にデータを取得します\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"]\n",
    ")\n",
    "#display(df_DATAs_BY_ALL_FILEs)\n",
    "print(\"\")\n",
    "print(\"ファイルごとに各文字列の個数をカウントします\")\n",
    "COUNT_COLUMNS = [\"col\",\"empty\", \"space\", \"-\", \"―\", \"—\", \"--\", \"Na\", \"na\", \"N/A\", \"n/a\", \"None\", \"none\", \"NULL\", \"null\", \"0\", \"alphabet\"]\n",
    "FINAL_COLUMNS = COUNT_COLUMNS + [\"ファイル名\", \"会計年\"] # 追跡を明確にするため\n",
    "df_placeholder_counts = pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "current_index = 0\n",
    "for (filename,year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    for col in df:\n",
    "        ser = df[col].fillna(pd.NA)\n",
    "        ser_str = ser.astype(str)\n",
    "        #display(ser_str)\n",
    "        row_data_tuple = (\n",
    "            col,\n",
    "            (ser_str == '').sum(), (ser_str == ' ').sum(),\n",
    "            (ser_str == '-').sum(), (ser_str == '―').sum(), (ser_str == '—').sum(), (ser_str == '--').sum(),\n",
    "            (ser_str == 'Na').sum(), (ser_str == 'na').sum(), (ser_str == 'N/A').sum(), (ser_str == 'n/a').sum(),\n",
    "            (ser_str == 'None').sum(), (ser_str == 'none').sum(), (ser_str == 'NULL').sum(), (ser_str == 'null').sum(),\n",
    "            (ser_str == '0').sum(), \n",
    "            ser_str.str.contains('[A-Za-z]', na=False).sum()\n",
    "        )\n",
    "        df_placeholder_counts.loc[current_index, COUNT_COLUMNS] = row_data_tuple\n",
    "        df_placeholder_counts.loc[current_index, \"ファイル名\"] = filename\n",
    "        df_placeholder_counts.loc[current_index, \"会計年\"] = year\n",
    "\n",
    "        current_index += 1\n",
    "display(df_placeholder_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420050e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"欠損値と疑われるコードを出力します。\")\n",
    "df = df_placeholder_counts.drop([\"ファイル名\",\"会計年\"],axis=1)\n",
    "df = df.groupby(\"col\").sum().sum()\n",
    "display(df)\n",
    "\n",
    "print(\"\")\n",
    "print(\"疑われるコードが含まれている列を出力します\")\n",
    "df = df_placeholder_counts.drop([\"ファイル名\",\"会計年\"],axis=1)\n",
    "df = df.groupby(\"col\").sum().sum()\n",
    "pl_list = df[df >0].index.tolist()\n",
    "df = df_placeholder_counts.drop([\"ファイル名\",\"会計年\"],axis=1)\n",
    "for value in pl_list:\n",
    "    list = df[df[value]>0][\"col\"].unique()\n",
    "    print(\"--------------\",value,\"のチェック----------------------------\")\n",
    "    display(list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"アルファベットが含まれているコードを出力します。\")\n",
    "for (filename, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    df_tmp = df[df[\"コード\"].str.contains(\"[A-Za-z]\", na=False)]\n",
    "    code_list = df_tmp[\"コード\"].to_list()\n",
    "    print(code_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ゼロが登録されているファイルと列を出力します。\")\n",
    "df = df_placeholder_counts\n",
    "df_0 = df.groupby([\"ファイル名\",\"col\"])[\"0\"].sum()\n",
    "df_0 = df_0[df_0>0].reset_index()\n",
    "print(df_0)\n",
    "print(df_0['col'].dtype)\n",
    "\n",
    "print(\"\")\n",
    "print(\"4つのファイルごとに該当列のリストを準備します\")\n",
    "df_temp = df_0[['ファイル名', 'col']]\n",
    "grouped = df_temp.groupby('ファイル名')\n",
    "col_lists = {\n",
    "    filename: group['col'].tolist()  # 各グループから 'col' 列を抽出し、tolist()でPythonリストに変換\n",
    "    for filename, group in grouped\n",
    "}\n",
    "print(col_lists)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ゼロの含まれるコードのデータを確認します。\")\n",
    "print(\"まずは年でわかれた各ファイルをつなぎ合わせます\")\n",
    "df_merge = {}\n",
    "for (filename, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    if filename not in df_merge:\n",
    "        df_merge[filename] = []\n",
    "    df_merge[filename].append(df)\n",
    "df_final = {}\n",
    "for filename in df_merge:\n",
    "    df_final[filename]  = pd.concat(df_merge[filename])\n",
    "display(df_final[\"fy-balance-sheet.csv\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"ファイルごとにゼロをもつコードの値をチェックします。\")\n",
    "filename = \"fy-profit-and-loss.csv\"\n",
    "print(\"ファイル名:\",filename)\n",
    "df_all = df_final[filename]\n",
    "for col_value in col_lists[filename]:\n",
    "    #print(filename, col)\n",
    "    df = df_all[df_all[col_value] == \"0\"]\n",
    "    code_list = df[\"コード\"].unique()\n",
    "    print(\"-----------------------\",col_value,\"-----------------------\")\n",
    "    for code in code_list:\n",
    "        display(df_all[df_all[\"コード\"] == code])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868eb6bf",
   "metadata": {},
   "source": [
    "### データ型の整合性確認\n",
    "ロードしたファイルの方が各列で共通になるようにします。\n",
    "<details>\n",
    "<summary><b>結果</b></summary>\n",
    "以下のように処理しています。\n",
    "\n",
    "- コード：string\n",
    "- 年度：timestump\n",
    "- その他：float\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"ファイル毎にデータを取得します\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"]\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"ハイフンを欠損値にします。\")\n",
    "df_missing_value_change = {\n",
    "    (filename, year): df.replace(\"-\", pd.NA)\n",
    "    for (filename, year), df in df_DATAs_BY_ALL_FILEs.items()\n",
    "}\n",
    "display(df_missing_value_change)\n",
    "\n",
    "print(\"\")\n",
    "print(\"数値化できるものはfloat化します。\")\n",
    "exclude_cols = [\"コード\", \"年度\"]  # 数値変換したくない列\n",
    "def safe_to_numeric(x):\n",
    "    try:\n",
    "        return pd.to_numeric(x)\n",
    "    except Exception:\n",
    "        return x  # 数値変換できなければそのまま返す\n",
    "df_type_to_float = {\n",
    "    key: df.assign(\n",
    "        **{\n",
    "            col: df[col].apply(safe_to_numeric) \n",
    "            for col in df.columns if col not in exclude_cols\n",
    "        }\n",
    "    )\n",
    "    for key, df in df_missing_value_change.items()\n",
    "}\n",
    "display(df_type_to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"各列のdtypeと要素のtypeを出力します。\")\n",
    "def check_column_types(df_DATAs_BY_ALL_FILEs):\n",
    "    COUNT_COLUMNS = [\"filename\", \"year\", \"col\", \"dtype\", \"sample_types\"]\n",
    "    df_type = pd.DataFrame(columns=COUNT_COLUMNS)\n",
    "    current_index = 0\n",
    "    for (filename, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "        for col in df.columns:\n",
    "            # 実際のデータ型を確認\n",
    "            dtype = df[col].dtype\n",
    "            sample_types = df[col].dropna().map(type).unique()\n",
    "            row_data_tuple = (filename, year, col, dtype, sample_types)\n",
    "            df_type.loc[current_index, COUNT_COLUMNS] = row_data_tuple\n",
    "            #print(row_data_tuple)\n",
    "            current_index +=1\n",
    "    return df_type\n",
    "df_type = check_column_types(df_type_to_float)\n",
    "display(df_type)\n",
    "\n",
    "print(\"\")\n",
    "print(\"dtypeがobjectの要素を検索します。\")\n",
    "display(df_type[df_type[\"dtype\"] == \"object\"][\"col\"].unique())\n",
    "\n",
    "print(\"\")\n",
    "print(\"dtypeがobjectの要素をstrにします。\")\n",
    "df = df_type_to_float\n",
    "df_type_change = {\n",
    "    #(filename, year): df.astype({col: 'string' for col in df.select_dtypes(include='object').columns})\n",
    "    (filename, year): (df.assign(コード=df[\"コード\"].astype(\"string\")) if \"コード\" in df.columns else df)\n",
    "    for (filename, year), df in df_type_to_float.items()\n",
    "}\n",
    "#display(df_type_change)\n",
    "print(\"\")\n",
    "print(\"日付はdatetimeにします。\")\n",
    "df_type_change = {\n",
    "    (filename, year): df.assign(年度=pd.to_datetime(df[\"年度\"], format=\"%Y/%m\"))\n",
    "    for (filename, year), df in df_type_change.items()\n",
    "}\n",
    "print(\"\")\n",
    "print(\"変更されているか確認します。\")\n",
    "df_type = check_column_types(df_type_change)\n",
    "#display(df_type[df_type[\"dtype\"] == \"object\"][\"col\"].unique())\n",
    "display(df_type)\n",
    "\n",
    "print(\"\")\n",
    "print(\"最後にsample_typesが正しいか確認します\")\n",
    "def chk_sample_type(df_type):\n",
    "    SAMPLE_TYPES_COLUMNS = [\"col\", \"sample_types\"]\n",
    "    df_sample_types = pd.DataFrame(columns=SAMPLE_TYPES_COLUMNS)\n",
    "    col_list = df_type[\"col\"].unique().tolist()\n",
    "    current_index=0\n",
    "    for col in col_list:\n",
    "        row_data_tuple = (\n",
    "            col,\n",
    "            df_type[df_type[\"col\"]==col][\"sample_types\"].astype(str).unique()\n",
    "        )\n",
    "        df_sample_types.loc[current_index, SAMPLE_TYPES_COLUMNS] = row_data_tuple\n",
    "        current_index +=1\n",
    "    return df_sample_types\n",
    "df_sample_types = chk_sample_type(df_type)\n",
    "#display(df_sample_types)\n",
    "\n",
    "print(\"\")\n",
    "print(\"float以外が含まれている列をfloatだけにします\")\n",
    "float_cols = df_sample_types[df_sample_types[\"sample_types\"].astype(str).str.contains(\"int\")]\n",
    "float_cols = float_cols[\"col\"].to_list()\n",
    "df_type_change = {\n",
    "    (filename, year): df.assign(**{\n",
    "        col: df[col].astype(float)\n",
    "        for col in float_cols\n",
    "        if col in df.columns\n",
    "    })\n",
    "    for (filename, year), df in df_type_change.items()\n",
    "}\n",
    "df_type = check_column_types(df_type_change)\n",
    "df_sample_types = chk_sample_type(df_type)\n",
    "display(df_sample_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449b485",
   "metadata": {},
   "source": [
    "### 初期品質の確認\n",
    "\n",
    "指標となる以下の数を確認し、必要な処理のプロセスを決定します。\n",
    "\n",
    "- コード\n",
    "- 年度\n",
    "- 列\n",
    "\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_rows', 60)\n",
    "\n",
    "print(\"\")\n",
    "print(\"処理済みデータをロードします。\")\n",
    "df_PROCESSED = df_type_change\n",
    "#display(df_PROCESSED)\n",
    "\n",
    "print(\"\")\n",
    "print(\"企業コード数、エンドの数、列数をファイルごとにまとめます。\")\n",
    "def get_file_info(df_PROCESSED):\n",
    "    df_file_info = pd.DataFrame(columns=[\"file\",\"year\",\"code_counts\",\"year_counts\",\"column_counts\"])\n",
    "    for (filename, year), df in df_PROCESSED.items():\n",
    "        # len(df_file_info)を次の新しい行のインデックスとして明示的に指定します。\n",
    "        df_file_info.loc[len(df_file_info)] = [\n",
    "            filename, year, df[\"コード\"].nunique(), df[\"年度\"].nunique(), df.columns.nunique()\n",
    "        ]\n",
    "    return df_file_info\n",
    "df_file_info = get_file_info(df_PROCESSED)\n",
    "#display(df_file_info)\n",
    "\n",
    "print(\"\")\n",
    "print(\"各ファイルの年推移を可視化します。\")\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"code_counts\",color=\"file\")\n",
    "#fig.show()\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"year_counts\",color=\"file\")\n",
    "#fig.show()\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"column_counts\",color=\"file\")\n",
    "#fig.show()\n",
    "\n",
    "print(\"\")\n",
    "print(\"最新年のファイルに登録されている年度を表示します。\")\n",
    "df = df_PROCESSED[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[\"年度\"].unique())\n",
    "\n",
    "print(\"\")\n",
    "print(\"最新年に登録されている過去の年度と過去のデータが同じか確認します\")\n",
    "print(\"まずは、年度を限定して、コードの一覧を見ます\")\n",
    "#display(df[df[\"年度\"]==\"2024/12\"][\"コード\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"コードを限定し、過去のデータファイルと同じかどうか調べます。\")\n",
    "df = df_PROCESSED[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[df[\"コード\"]==\"130A\"])\n",
    "df = df_PROCESSED[(settings[\"files\"][\"raw\"][0],2024)]\n",
    "#display(df[df[\"コード\"]==\"130A\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"最新年度にある過去のデータを取得し、過去のデータを更新します\")\n",
    "def update_df(df_by_files, latest_year):\n",
    "    df_all_datas_by_files = {}\n",
    "    cutoff_date = cutoff_date = pd.to_datetime(f\"{str(latest_year)}-01-01\")\n",
    "    #print(cutoff_date)\n",
    "    all_files = {key[0] for key in df_by_files.keys()}\n",
    "    for file in all_files:\n",
    "        df_source_raw = df_by_files.get((file, latest_year))\n",
    "        if df_source_raw is None:\n",
    "            print(f\"警告: {file} の2025年データが見つかりません。スキップします。\")\n",
    "            continue\n",
    "        # フィルタリング条件を作成: '年度'が基準日より小さいデータのみ抽出\n",
    "        df_update_source = df_source_raw[df_source_raw[\"年度\"] < cutoff_date]\n",
    "        df_update_source = df_update_source.set_index([\"コード\", \"年度\"])\n",
    "        #display(df_update_source)\n",
    "        # --- 2. 過去の全年のデータを更新 ---\n",
    "        all_years = {key[1] for key in df_by_files.keys() if key[0] == file}\n",
    "        for year in all_years:\n",
    "            df_target = df_by_files.get((file, year))\n",
    "            if df_target is None:\n",
    "                continue\n",
    "            df_target_indexed = df_target.set_index([\"コード\", \"年度\"])\n",
    "\n",
    "            df_target_indexed.update(df_update_source)\n",
    "            df_target_indexed = df_target_indexed.reset_index()\n",
    "            df_all_datas_by_files[(file, year)] = df_target_indexed\n",
    "    return df_all_datas_by_files\n",
    "\n",
    "df_PROCESSED_AFTER = update_df(df_PROCESSED, 2025)\n",
    "\n",
    "print(\"\")\n",
    "print(\"正しく処理が行われ、最新年に登録されている過去の年度と過去のデータが同じか確認します。\")\n",
    "df = df_PROCESSED_AFTER[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "display(df[df[\"コード\"]==\"130A\"])\n",
    "df = df_PROCESSED_AFTER[(settings[\"files\"][\"raw\"][0],2024)]\n",
    "display(df[df[\"コード\"]==\"130A\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"最後に最新年度にある過去のデータを消去します。\")\n",
    "cutoff_date = pd.to_datetime(\"2025-01-01\")\n",
    "for file, year in df_PROCESSED_AFTER.keys():\n",
    "    if year == 2025:\n",
    "        df = df_PROCESSED_AFTER[(file,year)]\n",
    "        df = df[df[\"年度\"] >= cutoff_date]\n",
    "        df_PROCESSED_AFTER[(file,year)] = df\n",
    "print(\"\")\n",
    "print(\"各ファイルの年推移をもう一度可視化し、改善していることを確かめます。\") \n",
    "df_file_info_after = get_file_info(df_PROCESSED_AFTER)\n",
    "df_file_info_after[\"区分\"] = \"処理後\"\n",
    "df_file_info_after = df_file_info_after.set_index([\"file\", \"year\"]).sort_index()\n",
    "\n",
    "df_file_info = get_file_info(df_PROCESSED)\n",
    "df_file_info[\"区分\"] = \"処理前\"\n",
    "df_file_info = df_file_info.set_index([\"file\", \"year\"]).sort_index()\n",
    "df_compare = pd.concat([df_file_info,df_file_info_after]).reset_index()\n",
    "display(df_compare)\n",
    "fig = px.line(df_compare, x=\"year\", y=\"code_counts\", color=\"file\", line_dash=\"区分\", markers=True)\n",
    "fig.update_layout(title=\"処理前後のコード数推移\", xaxis_title=\"年度\", yaxis_title=\"コード数\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9490d3",
   "metadata": {},
   "source": [
    "### 上場企業データのクリーニング\n",
    "\n",
    "<summary><b>結果</b></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38787973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ロードします。\n",
      "✅ ファイルは欠損していません。\n",
      "\n",
      "欠損値表現を確認します。\n",
      "\n",
      "欠損値処理をします。\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日付</th>\n",
       "      <th>コード</th>\n",
       "      <th>銘柄名</th>\n",
       "      <th>市場・商品区分</th>\n",
       "      <th>33業種コード</th>\n",
       "      <th>33業種区分</th>\n",
       "      <th>17業種コード</th>\n",
       "      <th>17業種区分</th>\n",
       "      <th>規模コード</th>\n",
       "      <th>規模区分</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1301</td>\n",
       "      <td>極洋</td>\n",
       "      <td>プライム（内国株式）</td>\n",
       "      <td>50</td>\n",
       "      <td>水産・農林業</td>\n",
       "      <td>1</td>\n",
       "      <td>食品</td>\n",
       "      <td>7</td>\n",
       "      <td>TOPIX Small 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1305</td>\n",
       "      <td>ｉＦｒｅｅＥＴＦ　ＴＯＰＩＸ（年１回決算型）</td>\n",
       "      <td>ETF・ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1306</td>\n",
       "      <td>ＮＥＸＴ　ＦＵＮＤＳ　ＴＯＰＩＸ連動型上場投信</td>\n",
       "      <td>ETF・ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1308</td>\n",
       "      <td>上場インデックスファンドＴＯＰＩＸ</td>\n",
       "      <td>ETF・ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1309</td>\n",
       "      <td>ＮＥＸＴ　ＦＵＮＤＳ　ＣｈｉｎａＡＭＣ・中国株式・上証５０連動型上場投信</td>\n",
       "      <td>ETF・ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9991</td>\n",
       "      <td>ジェコス</td>\n",
       "      <td>プライム（内国株式）</td>\n",
       "      <td>6050</td>\n",
       "      <td>卸売業</td>\n",
       "      <td>13</td>\n",
       "      <td>商社・卸売</td>\n",
       "      <td>7</td>\n",
       "      <td>TOPIX Small 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9993</td>\n",
       "      <td>ヤマザワ</td>\n",
       "      <td>スタンダード（内国株式）</td>\n",
       "      <td>6100</td>\n",
       "      <td>小売業</td>\n",
       "      <td>14</td>\n",
       "      <td>小売</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9994</td>\n",
       "      <td>やまや</td>\n",
       "      <td>スタンダード（内国株式）</td>\n",
       "      <td>6100</td>\n",
       "      <td>小売業</td>\n",
       "      <td>14</td>\n",
       "      <td>小売</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9996</td>\n",
       "      <td>サトー商会</td>\n",
       "      <td>スタンダード（内国株式）</td>\n",
       "      <td>6050</td>\n",
       "      <td>卸売業</td>\n",
       "      <td>13</td>\n",
       "      <td>商社・卸売</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9997</td>\n",
       "      <td>ベルーナ</td>\n",
       "      <td>プライム（内国株式）</td>\n",
       "      <td>6100</td>\n",
       "      <td>小売業</td>\n",
       "      <td>14</td>\n",
       "      <td>小売</td>\n",
       "      <td>6</td>\n",
       "      <td>TOPIX Small 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            日付   コード                                   銘柄名       市場・商品区分  \\\n",
       "0     20250930  1301                                    極洋    プライム（内国株式）   \n",
       "1     20250930  1305                ｉＦｒｅｅＥＴＦ　ＴＯＰＩＸ（年１回決算型）       ETF・ETN   \n",
       "2     20250930  1306               ＮＥＸＴ　ＦＵＮＤＳ　ＴＯＰＩＸ連動型上場投信       ETF・ETN   \n",
       "3     20250930  1308                     上場インデックスファンドＴＯＰＩＸ       ETF・ETN   \n",
       "4     20250930  1309  ＮＥＸＴ　ＦＵＮＤＳ　ＣｈｉｎａＡＭＣ・中国株式・上証５０連動型上場投信       ETF・ETN   \n",
       "...        ...   ...                                   ...           ...   \n",
       "4398  20250930  9991                                  ジェコス    プライム（内国株式）   \n",
       "4399  20250930  9993                                  ヤマザワ  スタンダード（内国株式）   \n",
       "4400  20250930  9994                                   やまや  スタンダード（内国株式）   \n",
       "4401  20250930  9996                                 サトー商会  スタンダード（内国株式）   \n",
       "4402  20250930  9997                                  ベルーナ    プライム（内国株式）   \n",
       "\n",
       "     33業種コード  33業種区分 17業種コード 17業種区分 規模コード           規模区分  \n",
       "0         50  水産・農林業       1     食品     7  TOPIX Small 2  \n",
       "1       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "2       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "3       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "4       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "...      ...     ...     ...    ...   ...            ...  \n",
       "4398    6050     卸売業      13  商社・卸売     7  TOPIX Small 2  \n",
       "4399    6100     小売業      14     小売  <NA>           <NA>  \n",
       "4400    6100     小売業      14     小売  <NA>           <NA>  \n",
       "4401    6050     卸売業      13  商社・卸売  <NA>           <NA>  \n",
       "4402    6100     小売業      14     小売     6  TOPIX Small 1  \n",
       "\n",
       "[4403 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>, <class 'pandas._libs.missing.NAType'>], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数値列を Int64 に変換します。\n",
      "\n",
      "列 '17業種コード' を int に変換中...\n",
      "\n",
      "列 '規模コード' を int に変換中...\n",
      "\n",
      "string 型に統一します。\n",
      "\n",
      "日付列を datetime に変換します。\n",
      "\n",
      "欠損値表現を確認します。\n",
      "\n",
      "データ型を確認します。\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nロードします。\")\n",
    "df_code_info = dl.load_on_startup(settings[\"data_path\"][\"reference\"], \"\", settings[\"files\"][\"reference\"])\n",
    "#display(df_code_info)\n",
    "dl.chk_file_missing(df_code_info)\n",
    "\n",
    "print(\"\\n欠損値表現を確認します。\")\n",
    "df_missing_values_expression = cu.chk_missing_values_expression(\n",
    "    df_code_info, filename=settings[\"files\"][\"reference\"], option_value=\"\"\n",
    ")\n",
    "#display(df_missing_values_expression)\n",
    "\n",
    "print(\"\\n欠損値処理をします。\")\n",
    "df_code_info_missing_change = df_code_info.replace({\"-\": pd.NA, \"\": pd.NA})\n",
    "\n",
    "display(df_code_info_missing_change)\n",
    "display(df_code_info_missing_change[\"33業種コード\"].map(type).unique())\n",
    "\n",
    "print(\"\\n数値列を Int64 に変換します。\")\n",
    "numeric_cols = [\"17業種コード\", \"規模コード\"]\n",
    "df = df_code_info_missing_change\n",
    "df = cu.convert_columns_type(df, numeric_cols, \"int\", True)\n",
    "\n",
    "print(\"\\nstring 型に統一します。\")\n",
    "for col in df.columns:\n",
    "    if col not in numeric_cols:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "\n",
    "print(\"\\n日付列を datetime に変換します。\")\n",
    "df[\"日付\"] = pd.to_datetime(df[\"日付\"], errors=\"coerce\", format=\"%Y%m%d\")\n",
    "df_type_change = df\n",
    "\n",
    "print(\"\")\n",
    "print(\"欠損値表現を確認します。\")\n",
    "df_missing_values_expression = cu.chk_missing_values_expression(df_type_change, filename=settings[\"files\"][\"reference\"], option_value=\"\")\n",
    "#display(df_missing_values_expression)\n",
    "\n",
    "print(\"\")\n",
    "print(\"データ型を確認します。\")\n",
    "df_type = cu.chk_dtype(df_type_change, filename=settings[\"files\"][\"reference\"], option_value=\"\")\n",
    "#display(df_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
