{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd607b5",
   "metadata": {},
   "source": [
    "## åˆæœŸè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe0f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” autoreload æœ‰åŠ¹åŒ–å®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# --- NotebookåˆæœŸè¨­å®š ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import src.config as cfg\n",
    "import src.data_loader as dl\n",
    "import src.data_cleaning_utils as cu\n",
    "print(\"ğŸ” autoreload æœ‰åŠ¹åŒ–å®Œäº†\")\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79cbfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'stock_screening',\n",
       " 'data_path': {'raw': './data/raw',\n",
       "  'interim': './data/interim',\n",
       "  'processed': './data/processed',\n",
       "  'reference': './data/reference'},\n",
       " 'files': {'raw': ['fy-balance-sheet.csv',\n",
       "   'fy-cash-flow-statement.csv',\n",
       "   'fy-profit-and-loss.csv',\n",
       "   'fy-stock-dividend.csv'],\n",
       "  'reference': 'CodeData.csv',\n",
       "  'interim': None,\n",
       "  'processed': None},\n",
       " 'years': [2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2015,\n",
       "  2016,\n",
       "  2017,\n",
       "  2018,\n",
       "  2019,\n",
       "  2020,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2024,\n",
       "  2025],\n",
       " 'na_values': [''],\n",
       " 'output': {'base_path': './output'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# è¨­å®šèª­ã¿è¾¼ã¿\n",
    "settings = cfg.load_settings(\"setting.yaml\")\n",
    "display(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6ff0d",
   "metadata": {},
   "source": [
    "## æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜\n",
    "ãƒ‡ãƒ¼ã‚¿ãŒæœ€ä½é™ã®å“è³ªåŸºæº–ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ã‚’ç¶²ç¾…çš„ã«ç¢ºèªã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ãƒ¼ãƒ‰ã‹ã‚‰ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ±ºå®šã—ã¾ã™ã€‚\n",
    "\n",
    "<details>\n",
    "<summary><b>çµæœ</b></summary>\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdaa036",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã®ç¢ºèª\n",
    "ãƒ•ã‚¡ã‚¤ãƒ«é‡è¤‡ã‚„ãƒ•ã‚¡ã‚¤ãƒ«æ¬ æã€ç ´å£ŠãŒãªã„ã‹ã‚’ç¢ºã‹ã‚ã€ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¢ºå®šã—ã¾ã™ã€‚\n",
    "<details>\n",
    "<summary><b>çµæœ</b></summary>\n",
    "\n",
    "ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ã‚„æ¬ æã¯ãªãã€æ­£ã—ããƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚  \n",
    "ä¿®æ­£å‡¦ç†ã¯ä¸è¦ã§ã™ã€‚\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"ãƒ•ã‚¡ã‚¤ãƒ«æ¯ã«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"]\n",
    ")\n",
    "display(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"æ¬¡ã«æ¬ ã‘ã¦ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã‹ç¢ºèªã—ã¾ã™\")\n",
    "def chk_file_missing(df_DATAs_BY_ALL_FILEs):\n",
    "    flg = True\n",
    "    for (filename,year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "        if df.empty:\n",
    "            print(\"âŒ \".filename,year,\"ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒç©ºã§ã™\")\n",
    "            flg = False\n",
    "    if flg:\n",
    "        print(\"âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ¬ æã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "chk_file_missing(df_DATAs_BY_ALL_FILEs)\n",
    "\n",
    "print(\"\")\n",
    "print(\"é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã‹ç¢ºèªã—ã¾ã™\")\n",
    "def df_hash(df, ignore_order=False):\n",
    "    data_only = df.copy().fillna(\"\").astype(str)\n",
    "    if ignore_order:\n",
    "        # è¡Œé †ã‚‚ç„¡è¦–ï¼ˆå…¨åˆ—ã‚½ãƒ¼ãƒˆã—ã¦ã‹ã‚‰æ¯”è¼ƒï¼‰\n",
    "        data_only = data_only.sort_values(by=data_only.columns.tolist()).reset_index(drop=True)\n",
    "    # åˆ—åã‚’ç„¡è¦–ã—ã¦å†…å®¹ã ã‘ã§ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ\n",
    "    h = hashlib.md5(pd.util.hash_pandas_object(data_only, index=True).values)\n",
    "    return h.hexdigest()\n",
    "hash_map = defaultdict(list)\n",
    "for (fname, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    h = df_hash(df, ignore_order=False)  # â†è¡Œé †ã‚’ç„¡è¦–ã—ãŸã„ãªã‚‰ True ã«\n",
    "    hash_map[h].append((fname, year))\n",
    "duplicates = {h: keys for h, keys in hash_map.items() if len(keys) > 1}\n",
    "if duplicates:\n",
    "    print(\"ğŸ” åŒã˜å†…å®¹ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ç„¡è¦–ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š\\n\")\n",
    "    for h, key_group in duplicates.items():\n",
    "        print(f\"ãƒãƒƒã‚·ãƒ¥: {h}\")\n",
    "        for fname, year in key_group:\n",
    "            print(f\"  - {fname}ï¼ˆ{year}ï¼‰\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"âœ… é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ã®ç¢ºèªã‚’çµ‚äº†ã—ã¾ã™ã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59706c4a",
   "metadata": {},
   "source": [
    "### æ¬ æå€¤è¡¨ç¾ã®ç¢ºèªã¨å‡¦ç†\n",
    "æ¬ æå€¤ã®è¡¨ç¾ã‚’ç¢ºèªã—ã€ä¿®æ­£ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ±ºå®šã—ã¾ã™ã€‚\n",
    "\n",
    "<details>\n",
    "<summary><b>çµæœ</b></summary>\n",
    "\n",
    "\"-\"ãŒæ¬ æå€¤ã¨ã—ã¦ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚  \n",
    "ã“ã‚Œã¯setting.yamlã®nan_valuesã«ç™»éŒ²ã—æ¬ æå€¤ã¨ã—ã¦èª­ã¿è¾¼ã¿ã¾ã™ã€‚  \n",
    "  \n",
    "ã¾ãŸã€ã‚¼ãƒ­ã‚‚ä½¿ã‚ã‚Œã¦ã„ã¾ã™ã€‚  \n",
    "ã‚¼ãƒ­ã¯å€¤ã¨ã—ã¦æ®‹ã—ã€å¿…è¦ã«å¿œã˜ã¦features_generatorã§å†è¨ˆç®—ã—æ›´æ–°ã—ã¾ã™ã€‚\n",
    "\n",
    "ä»¥ä¸‹ãŒã‚¼ãƒ­ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹é …ç›®ã§ã™ã€‚  \n",
    "{'fy-balance-sheet.csv': ['BPS', 'çŸ­æœŸå€Ÿå…¥é‡‘', 'ç·è³‡ç”£', 'è‡ªå·±è³‡æœ¬æ¯”ç‡', 'é•·æœŸå€Ÿå…¥é‡‘']  \n",
    "'fy-cash-flow-statement.csv': ['å–¶æ¥­CF', 'å–¶æ¥­CFãƒãƒ¼ã‚¸ãƒ³', 'æŠ•è³‡CF', 'ç¾é‡‘åŒç­‰ç‰©', 'è¨­å‚™æŠ•è³‡', 'è²¡å‹™CF']  \n",
    "'fy-profit-and-loss.csv': ['EPS', 'ROA', 'ROE', 'å–¶æ¥­åˆ©ç›Š', 'å£²ä¸Šé«˜', 'ç´”åˆ©ç›Š', 'çµŒå¸¸åˆ©ç›Š'],  \n",
    "'fy-stock-dividend.csv': ['ä¸€æ ªé…å½“', 'å‰°ä½™é‡‘ã®é…å½“', 'ç´”è³‡ç”£é…å½“ç‡', 'ç·é‚„å…ƒæ€§å‘', 'è‡ªç¤¾æ ªè²·ã„', 'é…å½“æ€§å‘']}\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¬ æå€¤ã®è¡¨ç¾ç¢ºèª\n",
    "print(\"\")\n",
    "print(\"ãƒ•ã‚¡ã‚¤ãƒ«æ¯ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"]\n",
    ")\n",
    "#display(df_DATAs_BY_ALL_FILEs)\n",
    "print(\"\")\n",
    "print(\"ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å„æ–‡å­—åˆ—ã®å€‹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™\")\n",
    "COUNT_COLUMNS = [\"col\",\"empty\", \"space\", \"-\", \"â€•\", \"â€”\", \"--\", \"Na\", \"na\", \"N/A\", \"n/a\", \"None\", \"none\", \"NULL\", \"null\", \"0\", \"alphabet\"]\n",
    "FINAL_COLUMNS = COUNT_COLUMNS + [\"ãƒ•ã‚¡ã‚¤ãƒ«å\", \"ä¼šè¨ˆå¹´\"] # è¿½è·¡ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚\n",
    "df_placeholder_counts = pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "current_index = 0\n",
    "for (filename,year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    for col in df:\n",
    "        ser = df[col].fillna(pd.NA)\n",
    "        ser_str = ser.astype(str)\n",
    "        #display(ser_str)\n",
    "        row_data_tuple = (\n",
    "            col,\n",
    "            (ser_str == '').sum(), (ser_str == ' ').sum(),\n",
    "            (ser_str == '-').sum(), (ser_str == 'â€•').sum(), (ser_str == 'â€”').sum(), (ser_str == '--').sum(),\n",
    "            (ser_str == 'Na').sum(), (ser_str == 'na').sum(), (ser_str == 'N/A').sum(), (ser_str == 'n/a').sum(),\n",
    "            (ser_str == 'None').sum(), (ser_str == 'none').sum(), (ser_str == 'NULL').sum(), (ser_str == 'null').sum(),\n",
    "            (ser_str == '0').sum(), \n",
    "            ser_str.str.contains('[A-Za-z]', na=False).sum()\n",
    "        )\n",
    "        df_placeholder_counts.loc[current_index, COUNT_COLUMNS] = row_data_tuple\n",
    "        df_placeholder_counts.loc[current_index, \"ãƒ•ã‚¡ã‚¤ãƒ«å\"] = filename\n",
    "        df_placeholder_counts.loc[current_index, \"ä¼šè¨ˆå¹´\"] = year\n",
    "\n",
    "        current_index += 1\n",
    "display(df_placeholder_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420050e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"æ¬ æå€¤ã¨ç–‘ã‚ã‚Œã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\")\n",
    "df = df_placeholder_counts.drop([\"ãƒ•ã‚¡ã‚¤ãƒ«å\",\"ä¼šè¨ˆå¹´\"],axis=1)\n",
    "df = df.groupby(\"col\").sum().sum()\n",
    "display(df)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ç–‘ã‚ã‚Œã‚‹ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹åˆ—ã‚’å‡ºåŠ›ã—ã¾ã™\")\n",
    "df = df_placeholder_counts.drop([\"ãƒ•ã‚¡ã‚¤ãƒ«å\",\"ä¼šè¨ˆå¹´\"],axis=1)\n",
    "df = df.groupby(\"col\").sum().sum()\n",
    "pl_list = df[df >0].index.tolist()\n",
    "df = df_placeholder_counts.drop([\"ãƒ•ã‚¡ã‚¤ãƒ«å\",\"ä¼šè¨ˆå¹´\"],axis=1)\n",
    "for value in pl_list:\n",
    "    list = df[df[value]>0][\"col\"].unique()\n",
    "    print(\"--------------\",value,\"ã®ãƒã‚§ãƒƒã‚¯----------------------------\")\n",
    "    display(list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\")\n",
    "for (filename, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    df_tmp = df[df[\"ã‚³ãƒ¼ãƒ‰\"].str.contains(\"[A-Za-z]\", na=False)]\n",
    "    code_list = df_tmp[\"ã‚³ãƒ¼ãƒ‰\"].to_list()\n",
    "    print(code_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ã‚¼ãƒ­ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¨åˆ—ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\")\n",
    "df = df_placeholder_counts\n",
    "df_0 = df.groupby([\"ãƒ•ã‚¡ã‚¤ãƒ«å\",\"col\"])[\"0\"].sum()\n",
    "df_0 = df_0[df_0>0].reset_index()\n",
    "print(df_0)\n",
    "print(df_0['col'].dtype)\n",
    "\n",
    "print(\"\")\n",
    "print(\"4ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è©²å½“åˆ—ã®ãƒªã‚¹ãƒˆã‚’æº–å‚™ã—ã¾ã™\")\n",
    "df_temp = df_0[['ãƒ•ã‚¡ã‚¤ãƒ«å', 'col']]\n",
    "grouped = df_temp.groupby('ãƒ•ã‚¡ã‚¤ãƒ«å')\n",
    "col_lists = {\n",
    "    filename: group['col'].tolist()  # å„ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰ 'col' åˆ—ã‚’æŠ½å‡ºã—ã€tolist()ã§Pythonãƒªã‚¹ãƒˆã«å¤‰æ›\n",
    "    for filename, group in grouped\n",
    "}\n",
    "print(col_lists)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ã‚¼ãƒ­ã®å«ã¾ã‚Œã‚‹ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¾ã™ã€‚\")\n",
    "print(\"ã¾ãšã¯å¹´ã§ã‚ã‹ã‚ŒãŸå„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¤ãªãåˆã‚ã›ã¾ã™\")\n",
    "df_merge = {}\n",
    "for (filename, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "    if filename not in df_merge:\n",
    "        df_merge[filename] = []\n",
    "    df_merge[filename].append(df)\n",
    "df_final = {}\n",
    "for filename in df_merge:\n",
    "    df_final[filename]  = pd.concat(df_merge[filename])\n",
    "display(df_final[\"fy-balance-sheet.csv\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¼ãƒ­ã‚’ã‚‚ã¤ã‚³ãƒ¼ãƒ‰ã®å€¤ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚\")\n",
    "filename = \"fy-profit-and-loss.csv\"\n",
    "print(\"ãƒ•ã‚¡ã‚¤ãƒ«å:\",filename)\n",
    "df_all = df_final[filename]\n",
    "for col_value in col_lists[filename]:\n",
    "    #print(filename, col)\n",
    "    df = df_all[df_all[col_value] == \"0\"]\n",
    "    code_list = df[\"ã‚³ãƒ¼ãƒ‰\"].unique()\n",
    "    print(\"-----------------------\",col_value,\"-----------------------\")\n",
    "    for code in code_list:\n",
    "        display(df_all[df_all[\"ã‚³ãƒ¼ãƒ‰\"] == code])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868eb6bf",
   "metadata": {},
   "source": [
    "### ãƒ‡ãƒ¼ã‚¿å‹ã®æ•´åˆæ€§ç¢ºèª\n",
    "ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ–¹ãŒå„åˆ—ã§å…±é€šã«ãªã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n",
    "<details>\n",
    "<summary><b>çµæœ</b></summary>\n",
    "ä»¥ä¸‹ã®ã‚ˆã†ã«å‡¦ç†ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "- ã‚³ãƒ¼ãƒ‰ï¼šstring\n",
    "- å¹´åº¦ï¼štimestump\n",
    "- ãã®ä»–ï¼šfloat\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"ãƒ•ã‚¡ã‚¤ãƒ«æ¯ã«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™\")\n",
    "df_DATAs_BY_ALL_FILEs = dl.load_data_by_files(\n",
    "    settings[\"data_path\"][\"raw\"],settings[\"years\"],settings[\"files\"][\"raw\"]\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"ãƒã‚¤ãƒ•ãƒ³ã‚’æ¬ æå€¤ã«ã—ã¾ã™ã€‚\")\n",
    "df_missing_value_change = {\n",
    "    (filename, year): df.replace(\"-\", pd.NA)\n",
    "    for (filename, year), df in df_DATAs_BY_ALL_FILEs.items()\n",
    "}\n",
    "display(df_missing_value_change)\n",
    "\n",
    "print(\"\")\n",
    "print(\"æ•°å€¤åŒ–ã§ãã‚‹ã‚‚ã®ã¯floatåŒ–ã—ã¾ã™ã€‚\")\n",
    "exclude_cols = [\"ã‚³ãƒ¼ãƒ‰\", \"å¹´åº¦\"]  # æ•°å€¤å¤‰æ›ã—ãŸããªã„åˆ—\n",
    "def safe_to_numeric(x):\n",
    "    try:\n",
    "        return pd.to_numeric(x)\n",
    "    except Exception:\n",
    "        return x  # æ•°å€¤å¤‰æ›ã§ããªã‘ã‚Œã°ãã®ã¾ã¾è¿”ã™\n",
    "df_type_to_float = {\n",
    "    key: df.assign(\n",
    "        **{\n",
    "            col: df[col].apply(safe_to_numeric) \n",
    "            for col in df.columns if col not in exclude_cols\n",
    "        }\n",
    "    )\n",
    "    for key, df in df_missing_value_change.items()\n",
    "}\n",
    "display(df_type_to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"å„åˆ—ã®dtypeã¨è¦ç´ ã®typeã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\")\n",
    "def check_column_types(df_DATAs_BY_ALL_FILEs):\n",
    "    COUNT_COLUMNS = [\"filename\", \"year\", \"col\", \"dtype\", \"sample_types\"]\n",
    "    df_type = pd.DataFrame(columns=COUNT_COLUMNS)\n",
    "    current_index = 0\n",
    "    for (filename, year), df in df_DATAs_BY_ALL_FILEs.items():\n",
    "        for col in df.columns:\n",
    "            # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèª\n",
    "            dtype = df[col].dtype\n",
    "            sample_types = df[col].dropna().map(type).unique()\n",
    "            row_data_tuple = (filename, year, col, dtype, sample_types)\n",
    "            df_type.loc[current_index, COUNT_COLUMNS] = row_data_tuple\n",
    "            #print(row_data_tuple)\n",
    "            current_index +=1\n",
    "    return df_type\n",
    "df_type = check_column_types(df_type_to_float)\n",
    "display(df_type)\n",
    "\n",
    "print(\"\")\n",
    "print(\"dtypeãŒobjectã®è¦ç´ ã‚’æ¤œç´¢ã—ã¾ã™ã€‚\")\n",
    "display(df_type[df_type[\"dtype\"] == \"object\"][\"col\"].unique())\n",
    "\n",
    "print(\"\")\n",
    "print(\"dtypeãŒobjectã®è¦ç´ ã‚’strã«ã—ã¾ã™ã€‚\")\n",
    "df = df_type_to_float\n",
    "df_type_change = {\n",
    "    #(filename, year): df.astype({col: 'string' for col in df.select_dtypes(include='object').columns})\n",
    "    (filename, year): (df.assign(ã‚³ãƒ¼ãƒ‰=df[\"ã‚³ãƒ¼ãƒ‰\"].astype(\"string\")) if \"ã‚³ãƒ¼ãƒ‰\" in df.columns else df)\n",
    "    for (filename, year), df in df_type_to_float.items()\n",
    "}\n",
    "#display(df_type_change)\n",
    "print(\"\")\n",
    "print(\"æ—¥ä»˜ã¯datetimeã«ã—ã¾ã™ã€‚\")\n",
    "df_type_change = {\n",
    "    (filename, year): df.assign(å¹´åº¦=pd.to_datetime(df[\"å¹´åº¦\"], format=\"%Y/%m\"))\n",
    "    for (filename, year), df in df_type_change.items()\n",
    "}\n",
    "print(\"\")\n",
    "print(\"å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚\")\n",
    "df_type = check_column_types(df_type_change)\n",
    "#display(df_type[df_type[\"dtype\"] == \"object\"][\"col\"].unique())\n",
    "display(df_type)\n",
    "\n",
    "print(\"\")\n",
    "print(\"æœ€å¾Œã«sample_typesãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¾ã™\")\n",
    "def chk_sample_type(df_type):\n",
    "    SAMPLE_TYPES_COLUMNS = [\"col\", \"sample_types\"]\n",
    "    df_sample_types = pd.DataFrame(columns=SAMPLE_TYPES_COLUMNS)\n",
    "    col_list = df_type[\"col\"].unique().tolist()\n",
    "    current_index=0\n",
    "    for col in col_list:\n",
    "        row_data_tuple = (\n",
    "            col,\n",
    "            df_type[df_type[\"col\"]==col][\"sample_types\"].astype(str).unique()\n",
    "        )\n",
    "        df_sample_types.loc[current_index, SAMPLE_TYPES_COLUMNS] = row_data_tuple\n",
    "        current_index +=1\n",
    "    return df_sample_types\n",
    "df_sample_types = chk_sample_type(df_type)\n",
    "#display(df_sample_types)\n",
    "\n",
    "print(\"\")\n",
    "print(\"floatä»¥å¤–ãŒå«ã¾ã‚Œã¦ã„ã‚‹åˆ—ã‚’floatã ã‘ã«ã—ã¾ã™\")\n",
    "float_cols = df_sample_types[df_sample_types[\"sample_types\"].astype(str).str.contains(\"int\")]\n",
    "float_cols = float_cols[\"col\"].to_list()\n",
    "df_type_change = {\n",
    "    (filename, year): df.assign(**{\n",
    "        col: df[col].astype(float)\n",
    "        for col in float_cols\n",
    "        if col in df.columns\n",
    "    })\n",
    "    for (filename, year), df in df_type_change.items()\n",
    "}\n",
    "df_type = check_column_types(df_type_change)\n",
    "df_sample_types = chk_sample_type(df_type)\n",
    "display(df_sample_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449b485",
   "metadata": {},
   "source": [
    "### åˆæœŸå“è³ªã®ç¢ºèª\n",
    "\n",
    "æŒ‡æ¨™ã¨ãªã‚‹ä»¥ä¸‹ã®æ•°ã‚’ç¢ºèªã—ã€å¿…è¦ãªå‡¦ç†ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ±ºå®šã—ã¾ã™ã€‚\n",
    "\n",
    "- ã‚³ãƒ¼ãƒ‰\n",
    "- å¹´åº¦\n",
    "- åˆ—\n",
    "\n",
    "<summary><b>çµæœ</b></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_rows', 60)\n",
    "\n",
    "print(\"\")\n",
    "print(\"å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\")\n",
    "df_PROCESSED = df_type_change\n",
    "#display(df_PROCESSED)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ä¼æ¥­ã‚³ãƒ¼ãƒ‰æ•°ã€ã‚¨ãƒ³ãƒ‰ã®æ•°ã€åˆ—æ•°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã¾ã¨ã‚ã¾ã™ã€‚\")\n",
    "def get_file_info(df_PROCESSED):\n",
    "    df_file_info = pd.DataFrame(columns=[\"file\",\"year\",\"code_counts\",\"year_counts\",\"column_counts\"])\n",
    "    for (filename, year), df in df_PROCESSED.items():\n",
    "        # len(df_file_info)ã‚’æ¬¡ã®æ–°ã—ã„è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦æ˜ç¤ºçš„ã«æŒ‡å®šã—ã¾ã™ã€‚\n",
    "        df_file_info.loc[len(df_file_info)] = [\n",
    "            filename, year, df[\"ã‚³ãƒ¼ãƒ‰\"].nunique(), df[\"å¹´åº¦\"].nunique(), df.columns.nunique()\n",
    "        ]\n",
    "    return df_file_info\n",
    "df_file_info = get_file_info(df_PROCESSED)\n",
    "#display(df_file_info)\n",
    "\n",
    "print(\"\")\n",
    "print(\"å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å¹´æ¨ç§»ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚\")\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"code_counts\",color=\"file\")\n",
    "#fig.show()\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"year_counts\",color=\"file\")\n",
    "#fig.show()\n",
    "fig = px.line(df_file_info,x=\"year\",y=\"column_counts\",color=\"file\")\n",
    "#fig.show()\n",
    "\n",
    "print(\"\")\n",
    "print(\"æœ€æ–°å¹´ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å¹´åº¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\")\n",
    "df = df_PROCESSED[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[\"å¹´åº¦\"].unique())\n",
    "\n",
    "print(\"\")\n",
    "print(\"æœ€æ–°å¹´ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹éå»ã®å¹´åº¦ã¨éå»ã®ãƒ‡ãƒ¼ã‚¿ãŒåŒã˜ã‹ç¢ºèªã—ã¾ã™\")\n",
    "print(\"ã¾ãšã¯ã€å¹´åº¦ã‚’é™å®šã—ã¦ã€ã‚³ãƒ¼ãƒ‰ã®ä¸€è¦§ã‚’è¦‹ã¾ã™\")\n",
    "#display(df[df[\"å¹´åº¦\"]==\"2024/12\"][\"ã‚³ãƒ¼ãƒ‰\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"ã‚³ãƒ¼ãƒ‰ã‚’é™å®šã—ã€éå»ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ã‹ã©ã†ã‹èª¿ã¹ã¾ã™ã€‚\")\n",
    "df = df_PROCESSED[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "#display(df[df[\"ã‚³ãƒ¼ãƒ‰\"]==\"130A\"])\n",
    "df = df_PROCESSED[(settings[\"files\"][\"raw\"][0],2024)]\n",
    "#display(df[df[\"ã‚³ãƒ¼ãƒ‰\"]==\"130A\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"æœ€æ–°å¹´åº¦ã«ã‚ã‚‹éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã¾ã™\")\n",
    "def update_df(df_by_files, latest_year):\n",
    "    df_all_datas_by_files = {}\n",
    "    cutoff_date = cutoff_date = pd.to_datetime(f\"{str(latest_year)}-01-01\")\n",
    "    #print(cutoff_date)\n",
    "    all_files = {key[0] for key in df_by_files.keys()}\n",
    "    for file in all_files:\n",
    "        df_source_raw = df_by_files.get((file, latest_year))\n",
    "        if df_source_raw is None:\n",
    "            print(f\"è­¦å‘Š: {file} ã®2025å¹´ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n",
    "            continue\n",
    "        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã‚’ä½œæˆ: 'å¹´åº¦'ãŒåŸºæº–æ—¥ã‚ˆã‚Šå°ã•ã„ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º\n",
    "        df_update_source = df_source_raw[df_source_raw[\"å¹´åº¦\"] < cutoff_date]\n",
    "        df_update_source = df_update_source.set_index([\"ã‚³ãƒ¼ãƒ‰\", \"å¹´åº¦\"])\n",
    "        #display(df_update_source)\n",
    "        # --- 2. éå»ã®å…¨å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–° ---\n",
    "        all_years = {key[1] for key in df_by_files.keys() if key[0] == file}\n",
    "        for year in all_years:\n",
    "            df_target = df_by_files.get((file, year))\n",
    "            if df_target is None:\n",
    "                continue\n",
    "            df_target_indexed = df_target.set_index([\"ã‚³ãƒ¼ãƒ‰\", \"å¹´åº¦\"])\n",
    "\n",
    "            df_target_indexed.update(df_update_source)\n",
    "            df_target_indexed = df_target_indexed.reset_index()\n",
    "            df_all_datas_by_files[(file, year)] = df_target_indexed\n",
    "    return df_all_datas_by_files\n",
    "\n",
    "df_PROCESSED_AFTER = update_df(df_PROCESSED, 2025)\n",
    "\n",
    "print(\"\")\n",
    "print(\"æ­£ã—ãå‡¦ç†ãŒè¡Œã‚ã‚Œã€æœ€æ–°å¹´ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹éå»ã®å¹´åº¦ã¨éå»ã®ãƒ‡ãƒ¼ã‚¿ãŒåŒã˜ã‹ç¢ºèªã—ã¾ã™ã€‚\")\n",
    "df = df_PROCESSED_AFTER[(settings[\"files\"][\"raw\"][0],2025)]\n",
    "display(df[df[\"ã‚³ãƒ¼ãƒ‰\"]==\"130A\"])\n",
    "df = df_PROCESSED_AFTER[(settings[\"files\"][\"raw\"][0],2024)]\n",
    "display(df[df[\"ã‚³ãƒ¼ãƒ‰\"]==\"130A\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"æœ€å¾Œã«æœ€æ–°å¹´åº¦ã«ã‚ã‚‹éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¶ˆå»ã—ã¾ã™ã€‚\")\n",
    "cutoff_date = pd.to_datetime(\"2025-01-01\")\n",
    "for file, year in df_PROCESSED_AFTER.keys():\n",
    "    if year == 2025:\n",
    "        df = df_PROCESSED_AFTER[(file,year)]\n",
    "        df = df[df[\"å¹´åº¦\"] >= cutoff_date]\n",
    "        df_PROCESSED_AFTER[(file,year)] = df\n",
    "print(\"\")\n",
    "print(\"å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å¹´æ¨ç§»ã‚’ã‚‚ã†ä¸€åº¦å¯è¦–åŒ–ã—ã€æ”¹å–„ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºã‹ã‚ã¾ã™ã€‚\") \n",
    "df_file_info_after = get_file_info(df_PROCESSED_AFTER)\n",
    "df_file_info_after[\"åŒºåˆ†\"] = \"å‡¦ç†å¾Œ\"\n",
    "df_file_info_after = df_file_info_after.set_index([\"file\", \"year\"]).sort_index()\n",
    "\n",
    "df_file_info = get_file_info(df_PROCESSED)\n",
    "df_file_info[\"åŒºåˆ†\"] = \"å‡¦ç†å‰\"\n",
    "df_file_info = df_file_info.set_index([\"file\", \"year\"]).sort_index()\n",
    "df_compare = pd.concat([df_file_info,df_file_info_after]).reset_index()\n",
    "display(df_compare)\n",
    "fig = px.line(df_compare, x=\"year\", y=\"code_counts\", color=\"file\", line_dash=\"åŒºåˆ†\", markers=True)\n",
    "fig.update_layout(title=\"å‡¦ç†å‰å¾Œã®ã‚³ãƒ¼ãƒ‰æ•°æ¨ç§»\", xaxis_title=\"å¹´åº¦\", yaxis_title=\"ã‚³ãƒ¼ãƒ‰æ•°\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9490d3",
   "metadata": {},
   "source": [
    "### ä¸Šå ´ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "\n",
    "<summary><b>çµæœ</b></summary>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38787973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
      "âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ¬ æã—ã¦ã„ã¾ã›ã‚“ã€‚\n",
      "\n",
      "æ¬ æå€¤è¡¨ç¾ã‚’ç¢ºèªã—ã¾ã™ã€‚\n",
      "\n",
      "æ¬ æå€¤å‡¦ç†ã‚’ã—ã¾ã™ã€‚\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>æ—¥ä»˜</th>\n",
       "      <th>ã‚³ãƒ¼ãƒ‰</th>\n",
       "      <th>éŠ˜æŸ„å</th>\n",
       "      <th>å¸‚å ´ãƒ»å•†å“åŒºåˆ†</th>\n",
       "      <th>33æ¥­ç¨®ã‚³ãƒ¼ãƒ‰</th>\n",
       "      <th>33æ¥­ç¨®åŒºåˆ†</th>\n",
       "      <th>17æ¥­ç¨®ã‚³ãƒ¼ãƒ‰</th>\n",
       "      <th>17æ¥­ç¨®åŒºåˆ†</th>\n",
       "      <th>è¦æ¨¡ã‚³ãƒ¼ãƒ‰</th>\n",
       "      <th>è¦æ¨¡åŒºåˆ†</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1301</td>\n",
       "      <td>æ¥µæ´‹</td>\n",
       "      <td>ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰</td>\n",
       "      <td>50</td>\n",
       "      <td>æ°´ç”£ãƒ»è¾²æ—æ¥­</td>\n",
       "      <td>1</td>\n",
       "      <td>é£Ÿå“</td>\n",
       "      <td>7</td>\n",
       "      <td>TOPIX Small 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1305</td>\n",
       "      <td>ï½‰ï¼¦ï½’ï½…ï½…ï¼¥ï¼´ï¼¦ã€€ï¼´ï¼¯ï¼°ï¼©ï¼¸ï¼ˆå¹´ï¼‘å›æ±ºç®—å‹ï¼‰</td>\n",
       "      <td>ETFãƒ»ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1306</td>\n",
       "      <td>ï¼®ï¼¥ï¼¸ï¼´ã€€ï¼¦ï¼µï¼®ï¼¤ï¼³ã€€ï¼´ï¼¯ï¼°ï¼©ï¼¸é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡</td>\n",
       "      <td>ETFãƒ»ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1308</td>\n",
       "      <td>ä¸Šå ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ãƒ³ãƒ‰ï¼´ï¼¯ï¼°ï¼©ï¼¸</td>\n",
       "      <td>ETFãƒ»ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250930</td>\n",
       "      <td>1309</td>\n",
       "      <td>ï¼®ï¼¥ï¼¸ï¼´ã€€ï¼¦ï¼µï¼®ï¼¤ï¼³ã€€ï¼£ï½ˆï½‰ï½ï½ï¼¡ï¼­ï¼£ãƒ»ä¸­å›½æ ªå¼ãƒ»ä¸Šè¨¼ï¼•ï¼é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡</td>\n",
       "      <td>ETFãƒ»ETN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9991</td>\n",
       "      <td>ã‚¸ã‚§ã‚³ã‚¹</td>\n",
       "      <td>ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰</td>\n",
       "      <td>6050</td>\n",
       "      <td>å¸å£²æ¥­</td>\n",
       "      <td>13</td>\n",
       "      <td>å•†ç¤¾ãƒ»å¸å£²</td>\n",
       "      <td>7</td>\n",
       "      <td>TOPIX Small 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9993</td>\n",
       "      <td>ãƒ¤ãƒã‚¶ãƒ¯</td>\n",
       "      <td>ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰</td>\n",
       "      <td>6100</td>\n",
       "      <td>å°å£²æ¥­</td>\n",
       "      <td>14</td>\n",
       "      <td>å°å£²</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9994</td>\n",
       "      <td>ã‚„ã¾ã‚„</td>\n",
       "      <td>ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰</td>\n",
       "      <td>6100</td>\n",
       "      <td>å°å£²æ¥­</td>\n",
       "      <td>14</td>\n",
       "      <td>å°å£²</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9996</td>\n",
       "      <td>ã‚µãƒˆãƒ¼å•†ä¼š</td>\n",
       "      <td>ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰</td>\n",
       "      <td>6050</td>\n",
       "      <td>å¸å£²æ¥­</td>\n",
       "      <td>13</td>\n",
       "      <td>å•†ç¤¾ãƒ»å¸å£²</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>20250930</td>\n",
       "      <td>9997</td>\n",
       "      <td>ãƒ™ãƒ«ãƒ¼ãƒŠ</td>\n",
       "      <td>ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰</td>\n",
       "      <td>6100</td>\n",
       "      <td>å°å£²æ¥­</td>\n",
       "      <td>14</td>\n",
       "      <td>å°å£²</td>\n",
       "      <td>6</td>\n",
       "      <td>TOPIX Small 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            æ—¥ä»˜   ã‚³ãƒ¼ãƒ‰                                   éŠ˜æŸ„å       å¸‚å ´ãƒ»å•†å“åŒºåˆ†  \\\n",
       "0     20250930  1301                                    æ¥µæ´‹    ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰   \n",
       "1     20250930  1305                ï½‰ï¼¦ï½’ï½…ï½…ï¼¥ï¼´ï¼¦ã€€ï¼´ï¼¯ï¼°ï¼©ï¼¸ï¼ˆå¹´ï¼‘å›æ±ºç®—å‹ï¼‰       ETFãƒ»ETN   \n",
       "2     20250930  1306               ï¼®ï¼¥ï¼¸ï¼´ã€€ï¼¦ï¼µï¼®ï¼¤ï¼³ã€€ï¼´ï¼¯ï¼°ï¼©ï¼¸é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡       ETFãƒ»ETN   \n",
       "3     20250930  1308                     ä¸Šå ´ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ãƒ³ãƒ‰ï¼´ï¼¯ï¼°ï¼©ï¼¸       ETFãƒ»ETN   \n",
       "4     20250930  1309  ï¼®ï¼¥ï¼¸ï¼´ã€€ï¼¦ï¼µï¼®ï¼¤ï¼³ã€€ï¼£ï½ˆï½‰ï½ï½ï¼¡ï¼­ï¼£ãƒ»ä¸­å›½æ ªå¼ãƒ»ä¸Šè¨¼ï¼•ï¼é€£å‹•å‹ä¸Šå ´æŠ•ä¿¡       ETFãƒ»ETN   \n",
       "...        ...   ...                                   ...           ...   \n",
       "4398  20250930  9991                                  ã‚¸ã‚§ã‚³ã‚¹    ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰   \n",
       "4399  20250930  9993                                  ãƒ¤ãƒã‚¶ãƒ¯  ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰   \n",
       "4400  20250930  9994                                   ã‚„ã¾ã‚„  ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰   \n",
       "4401  20250930  9996                                 ã‚µãƒˆãƒ¼å•†ä¼š  ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ï¼ˆå†…å›½æ ªå¼ï¼‰   \n",
       "4402  20250930  9997                                  ãƒ™ãƒ«ãƒ¼ãƒŠ    ãƒ—ãƒ©ã‚¤ãƒ ï¼ˆå†…å›½æ ªå¼ï¼‰   \n",
       "\n",
       "     33æ¥­ç¨®ã‚³ãƒ¼ãƒ‰  33æ¥­ç¨®åŒºåˆ† 17æ¥­ç¨®ã‚³ãƒ¼ãƒ‰ 17æ¥­ç¨®åŒºåˆ† è¦æ¨¡ã‚³ãƒ¼ãƒ‰           è¦æ¨¡åŒºåˆ†  \n",
       "0         50  æ°´ç”£ãƒ»è¾²æ—æ¥­       1     é£Ÿå“     7  TOPIX Small 2  \n",
       "1       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "2       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "3       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "4       <NA>    <NA>    <NA>   <NA>  <NA>           <NA>  \n",
       "...      ...     ...     ...    ...   ...            ...  \n",
       "4398    6050     å¸å£²æ¥­      13  å•†ç¤¾ãƒ»å¸å£²     7  TOPIX Small 2  \n",
       "4399    6100     å°å£²æ¥­      14     å°å£²  <NA>           <NA>  \n",
       "4400    6100     å°å£²æ¥­      14     å°å£²  <NA>           <NA>  \n",
       "4401    6050     å¸å£²æ¥­      13  å•†ç¤¾ãƒ»å¸å£²  <NA>           <NA>  \n",
       "4402    6100     å°å£²æ¥­      14     å°å£²     6  TOPIX Small 1  \n",
       "\n",
       "[4403 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>, <class 'pandas._libs.missing.NAType'>], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æ•°å€¤åˆ—ã‚’ Int64 ã«å¤‰æ›ã—ã¾ã™ã€‚\n",
      "\n",
      "åˆ— '17æ¥­ç¨®ã‚³ãƒ¼ãƒ‰' ã‚’ int ã«å¤‰æ›ä¸­...\n",
      "\n",
      "åˆ— 'è¦æ¨¡ã‚³ãƒ¼ãƒ‰' ã‚’ int ã«å¤‰æ›ä¸­...\n",
      "\n",
      "string å‹ã«çµ±ä¸€ã—ã¾ã™ã€‚\n",
      "\n",
      "æ—¥ä»˜åˆ—ã‚’ datetime ã«å¤‰æ›ã—ã¾ã™ã€‚\n",
      "\n",
      "æ¬ æå€¤è¡¨ç¾ã‚’ç¢ºèªã—ã¾ã™ã€‚\n",
      "\n",
      "ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèªã—ã¾ã™ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\")\n",
    "df_code_info = dl.load_on_startup(settings[\"data_path\"][\"reference\"], \"\", settings[\"files\"][\"reference\"])\n",
    "#display(df_code_info)\n",
    "dl.chk_file_missing(df_code_info)\n",
    "\n",
    "print(\"\\næ¬ æå€¤è¡¨ç¾ã‚’ç¢ºèªã—ã¾ã™ã€‚\")\n",
    "df_missing_values_expression = cu.chk_missing_values_expression(\n",
    "    df_code_info, filename=settings[\"files\"][\"reference\"], option_value=\"\"\n",
    ")\n",
    "#display(df_missing_values_expression)\n",
    "\n",
    "print(\"\\næ¬ æå€¤å‡¦ç†ã‚’ã—ã¾ã™ã€‚\")\n",
    "df_code_info_missing_change = df_code_info.replace({\"-\": pd.NA, \"\": pd.NA})\n",
    "\n",
    "display(df_code_info_missing_change)\n",
    "display(df_code_info_missing_change[\"33æ¥­ç¨®ã‚³ãƒ¼ãƒ‰\"].map(type).unique())\n",
    "\n",
    "print(\"\\næ•°å€¤åˆ—ã‚’ Int64 ã«å¤‰æ›ã—ã¾ã™ã€‚\")\n",
    "numeric_cols = [\"17æ¥­ç¨®ã‚³ãƒ¼ãƒ‰\", \"è¦æ¨¡ã‚³ãƒ¼ãƒ‰\"]\n",
    "df = df_code_info_missing_change\n",
    "df = cu.convert_columns_type(df, numeric_cols, \"int\", True)\n",
    "\n",
    "print(\"\\nstring å‹ã«çµ±ä¸€ã—ã¾ã™ã€‚\")\n",
    "for col in df.columns:\n",
    "    if col not in numeric_cols:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "\n",
    "print(\"\\næ—¥ä»˜åˆ—ã‚’ datetime ã«å¤‰æ›ã—ã¾ã™ã€‚\")\n",
    "df[\"æ—¥ä»˜\"] = pd.to_datetime(df[\"æ—¥ä»˜\"], errors=\"coerce\", format=\"%Y%m%d\")\n",
    "df_type_change = df\n",
    "\n",
    "print(\"\")\n",
    "print(\"æ¬ æå€¤è¡¨ç¾ã‚’ç¢ºèªã—ã¾ã™ã€‚\")\n",
    "df_missing_values_expression = cu.chk_missing_values_expression(df_type_change, filename=settings[\"files\"][\"reference\"], option_value=\"\")\n",
    "#display(df_missing_values_expression)\n",
    "\n",
    "print(\"\")\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèªã—ã¾ã™ã€‚\")\n",
    "df_type = cu.chk_dtype(df_type_change, filename=settings[\"files\"][\"reference\"], option_value=\"\")\n",
    "#display(df_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
