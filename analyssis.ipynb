{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 分析の流れ\n",
    "<details>\n",
    "<summary><b>目次</b></summary>\n",
    "\n",
    "1. **データ読み込み**\n",
    "1. **欠損値処理**\n",
    "    - 欠損列処理  \n",
    "    - 欠損値処理  \n",
    "    - 異常値処理  \n",
    "1. **集計**\n",
    "1. **データ出力**\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 初期設定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポートとpyモジュールのリロード設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 autoreload 有効化完了\n"
     ]
    }
   ],
   "source": [
    "# --- Notebook初期設定 ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "import src.config as cfg\n",
    "import src.data_loader as dl\n",
    "import src.eda as eda\n",
    "import src.preprocess as pp\n",
    "#importlib.reload(cfg)\n",
    "#importlib.reload(pp)\n",
    "#importlib.reload(dl)\n",
    "#importlib.reload(eda)\n",
    "\n",
    "print(\"🔁 autoreload 有効化完了\")\n",
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定値の読み込み\n",
    "yamlファイルから設定を読み込みま\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project_name': 'stock_screening_preproc',\n",
       " 'data_path': './data',\n",
       " 'years': [2010,\n",
       "  2011,\n",
       "  2012,\n",
       "  2013,\n",
       "  2014,\n",
       "  2015,\n",
       "  2016,\n",
       "  2017,\n",
       "  2018,\n",
       "  2019,\n",
       "  2020,\n",
       "  2021,\n",
       "  2022,\n",
       "  2023,\n",
       "  2024,\n",
       "  2025],\n",
       " 'files': ['fy-balance-sheet.csv',\n",
       "  'fy-cash-flow-statement.csv',\n",
       "  'fy-profit-and-loss.csv',\n",
       "  'fy-stock-dividend.csv'],\n",
       " 'files_reference': ['CodeData.csv'],\n",
       " 'na_values': ['-', '0', 'NaN', ''],\n",
       " 'output': {'base_path': './output',\n",
       "  'files': {'fy-balance-sheet.csv': 'all_fy-balance-sheet.csv',\n",
       "   'fy-cash-flow-statement.csv': 'all_fy-cash-flow-statement.csv',\n",
       "   'fy-profit-and-loss.csv': 'all_fy-profit-and-loss.csv',\n",
       "   'fy-stock-dividend.csv': 'all_fy-stock-dividend.csv'}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 設定読み込み\n",
    "settings = cfg.load_settings(\"setting.yaml\")\n",
    "display(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 欠損列の確認\n",
    "4つファイルの列が各年度で同じかを目視で確認しておきます。\n",
    "問題がある場合は処理します。\n",
    "<details><summary><b>結果</b></summary>\n",
    "すべてのファイルで同じ列が登録されています。問題ありません。\n",
    "\n",
    "- fy-balance-sheet.csv\n",
    "- fy-cash-flow-statement.csv\n",
    "- fy-profit-and-loss.csv\n",
    "- fy-stock-dividend.csv\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.chk_yearly_header(settings[\"data_path\"], settings[\"years\"], settings[\"files\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 欠損値表現の確認\n",
    "プレースホルダやゼロをチェックし、NaNのデータを特定します。  \n",
    "NaNのデータは、setting.yamlの`na_values`で指定します。\n",
    "\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_valuesに\"\"だけ指定し、他のプレースホルダをチェックする\"\n",
    "df = dl.load_yearly_data(settings[\"data_path\"], settings[\"years\"], settings[\"files\"], na_values=[\"\"])\n",
    "df = pp.merge_all_data(df)\n",
    "df_missing_values_expression = eda.chk_missing_value_exploration(df)\n",
    "display(df_missing_values_expression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 データ読み込み\n",
    "データファイルとコード情報ファイルを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.config failed: Traceback (most recent call last):\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 322, in check\n",
      "    elif self.deduper_reloader.maybe_reload_module(m):\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 545, in maybe_reload_module\n",
      "    new_source_code = f.read()\n",
      "UnicodeDecodeError: 'cp932' codec can't decode byte 0x82 in position 150: illegal multibyte sequence\n",
      "]\n",
      "[autoreload of src.data_loader failed: Traceback (most recent call last):\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 322, in check\n",
      "    elif self.deduper_reloader.maybe_reload_module(m):\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 545, in maybe_reload_module\n",
      "    new_source_code = f.read()\n",
      "UnicodeDecodeError: 'cp932' codec can't decode byte 0x87 in position 144: illegal multibyte sequence\n",
      "]\n",
      "[autoreload of src.eda failed: Traceback (most recent call last):\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 322, in check\n",
      "    elif self.deduper_reloader.maybe_reload_module(m):\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 545, in maybe_reload_module\n",
      "    new_source_code = f.read()\n",
      "UnicodeDecodeError: 'cp932' codec can't decode byte 0x87 in position 123: illegal multibyte sequence\n",
      "]\n",
      "[autoreload of src.preprocess failed: Traceback (most recent call last):\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 322, in check\n",
      "    elif self.deduper_reloader.maybe_reload_module(m):\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^\n",
      "  File \"c:\\dev\\cases\\portfolio\\003_stock_screening_preproc\\.venv\\Lib\\site-packages\\IPython\\extensions\\deduperreload\\deduperreload.py\", line 545, in maybe_reload_module\n",
      "    new_source_code = f.read()\n",
      "UnicodeDecodeError: 'cp932' codec can't decode byte 0x87 in position 118: illegal multibyte sequence\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ALL_BY_FILEs = dl.load_yearly_data(settings[\"data_path\"], settings[\"years\"], settings[\"files\"], settings[\"na_values\"])\n",
    "df_ALL_DATAs = pp.merge_all_data(df_ALL_BY_FILEs)\n",
    "code_list_by_latest_year = pp.filter_code_by_latest_year(df_ALL_DATAs)\n",
    "display(len(code_list_by_latest_year))\n",
    "#subset = df_by_code.loc[df_by_code.index.isin(codes)] # 企業コードのデータ抽出\n",
    "df_ALL_DATAs = df_ALL_DATAs[df_ALL_DATAs[\"コード\"].isin(code_list_by_latest_year)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 欠損値の傾向を大まかに確認する\n",
    "ここでは、後の分析・スクリーニングの処理を適切に設計するため、欠損値の傾向を確認します。  \n",
    "<details><summary><b>分析内容</b></summary>\n",
    "\n",
    "1. 列ごとの欠損値の割合を確認する\n",
    "1. 年ごとの欠損率の傾向を確認する\n",
    "1. 企業コードごとの欠損率の傾向を確認する\n",
    "<br>\n",
    "</details>\n",
    "<details><summary><b>結果と考察</b></summary>\n",
    "\n",
    "1. 列ごとの欠損値の割合\n",
    "    * 短期借入金、長期借入金、自社株買いの欠損割合は高いため、その傾向を詳細分析\n",
    "    * 重要指標であるROA、ROE、配当性向、純資産配当率の欠損傾向の詳細分析\n",
    "    * ROA、ROE、配当性向、純資産配当率の置き換え・補足可能かを検討\n",
    "1. 年ごとの欠損率の傾向\n",
    "    * 純資産配当率（DOE)は重要指標のため2013年以降が望ましい\n",
    "1. 企業コードごとの欠損率の傾向を確認する\n",
    "    * 半数以上を占める0.01-0.11の欠損パターンを確認\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 列ごとの欠損値の割合を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_ALL_DATAs.drop(columns=[\"コード\", \"年度\"]).isna().mean()\n",
    "fig = px.bar(df_combined, x=df_combined.index, y=df_combined.values, labels={\"x\":\"項目\",\"y\":\"欠損率\"}, title=\"平均欠損率\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 年ごとの欠損率の傾向を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ALL_DATAs.copy()\n",
    "df[\"年度_年\"] = df[\"年度\"].astype(str).str[:4].astype(int)\n",
    "missing_ratio_by_year = (\n",
    "    df.drop(columns=[\"コード\", \"年度\"])\n",
    "    .groupby(\"年度_年\")\n",
    "    .agg(lambda g: g.isnull().mean())\n",
    "    .reset_index()\n",
    ")\n",
    "missing_ratio_by_year = missing_ratio_by_year.set_index(\"年度_年\")\n",
    "fig = px.line(\n",
    "    missing_ratio_by_year,\n",
    "    title=\"年度別 欠損値割合の推移\",\n",
    "    markers=True,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☑️ 企業コードごとの欠損率の傾向を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コードごとに欠損率を計算\n",
    "missing_score = (\n",
    "    df_ALL_DATAs\n",
    "    .drop(\"年度\",axis=1)\n",
    "    .groupby(\"コード\")\n",
    "    .agg(lambda x: x.isnull().mean())  # 各列ごとの欠損率\n",
    "    .mean(axis=1)                      # 列平均\n",
    "    .reset_index(name=\"平均欠損率\")\n",
    ")\n",
    "#display(missing_score)\n",
    "fig = px.histogram(missing_score, x=\"平均欠損率\",nbins=50,\n",
    "    title=\"全企業の欠損率分布\", labels={\"平均欠損率\": \"平均欠損率\"},histnorm=\"percent\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧽 欠損値の傾向を詳細に分析する\n",
    "ここでは、大まかな傾向から、詳細に欠損値の傾向を確認します。  \n",
    "<details><summary><b>分析内容</b></summary>\n",
    "\n",
    "1. 短期借入金、長期借入金、自社株買いの欠損割合は高いため、その傾向を詳細分析\n",
    "1. 重要指標であるROA、ROE、配当性向、純資産配当率の欠損傾向の詳細分析\n",
    "1. ROA、ROE、配当性向、純資産配当率の置き換え・補足可能かを検討\n",
    "1. 設備投資の欠損率が2025年に上がっている原因の分析\n",
    "1. 半数以上を占める0.01-0.11の欠損パターンを確認\n",
    "\n",
    "<br>\n",
    "</details>\n",
    "<details><summary><b>結果と考察</b></summary>\n",
    "\n",
    "- fy-balance-sheet.csv\n",
    "- fy-cash-flow-statement.csv\n",
    "- fy-profit-and-loss.csv\n",
    "- fy-stock-dividend.csv\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 短期借入金、長期借入金、自社株買いの傾向を詳細分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_ALL_DATAs[[\"コード\", \"年度\", \"短期借入金\", \"長期借入金\", \"自社株買い\"]].copy()\n",
    "#display(df_target)\n",
    "\n",
    "# 欠損率割合いの分布\n",
    "missing_ratio_by_code = (\n",
    "    df_target.groupby(\"コード\")[[\"短期借入金\", \"長期借入金\", \"自社株買い\"]]\n",
    "      .apply(lambda g: g.isnull().mean())\n",
    "      .reset_index()\n",
    ")\n",
    "#display(missing_ratio_by_code.info())\n",
    "fig = px.histogram(missing_ratio_by_code, x=[\"短期借入金\", \"長期借入金\", \"自社株買い\"],\n",
    "    title=\"短期借入金、長期借入金、自社株買いの欠損率分布\", labels={\"value\": \"欠損率\"}, barmode=\"group\", histnorm=\"percent\")\n",
    "#fig.show()\n",
    "\n",
    "# 各企業の欠損率を計算し、\"常時欠損\" を抽出\n",
    "codes_list = {}\n",
    "missing_ratio_by_code = missing_ratio_by_code.set_index(\"コード\")\n",
    "#display(missing_ratio_by_code)\n",
    "for col in [\"短期借入金\", \"長期借入金\", \"自社株買い\"]:\n",
    "    df = missing_ratio_by_code[col]\n",
    "    df = df[(df == 1.0)]\n",
    "    codes_list[col] = df.index.tolist()\n",
    "    #display(len(codes_list[col]))\n",
    "#display(codes_list)\n",
    "\n",
    "# 業種に偏りがあるか確認\n",
    "p = os.path.join(settings[\"data_path\"], settings[\"files_reference\"][0])\n",
    "df = pd.read_csv(p,header=0,na_values=[])\n",
    "\n",
    "# 全体データ\n",
    "df_industry_33 = df[[\"コード\",\"33業種区分\"]].drop_duplicates().set_index(\"コード\")\n",
    "df_industry_33[\"区分\"] = \"全体\"\n",
    "df_industry_17 = df[[\"コード\",\"17業種区分\"]].drop_duplicates().set_index(\"コード\")\n",
    "df_industry_17[\"区分\"] = \"全体\"\n",
    "#display(df_industry_17)\n",
    "#display(df_industry_33)\n",
    "\n",
    "# subsetデータ\n",
    "df_sub_33 = {}\n",
    "for col in [\"短期借入金\", \"長期借入金\", \"自社株買い\"]:\n",
    "    df_sub_33[col] = df[df[\"コード\"].isin(codes_list[col])].copy()\n",
    "    df_sub_33[col] = df_sub_33[col][[\"コード\",\"33業種区分\"]].drop_duplicates().set_index(\"コード\")\n",
    "    df_sub_33[col][\"区分\"] = f\"常時欠損_{col}\"\n",
    "    #display(df_sub_33[col])\n",
    "    \n",
    "# 結合\n",
    "df_combined = pd.concat([df_industry_33, df_sub_33[\"短期借入金\"], df_sub_33[\"長期借入金\"], df_sub_33[\"自社株買い\"]])\n",
    "\n",
    "# Plotly Expressで可視化\n",
    "fig = px.histogram(\n",
    "    df_combined,\n",
    "    x=\"33業種区分\",\n",
    "    color=\"区分\",\n",
    "    barmode=\"group\",\n",
    "    histnorm=\"percent\",  # ← 割合表示\n",
    "    title=\"33業種区分別の構成比比較（全体 vs 抽出subset）\"\n",
    ")\n",
    "fig.show()\n",
    "# \"\"\"\n",
    "# 時価総額に偏りがあるか確認\n",
    "\n",
    "\n",
    "\"\"\"target_file = files[0]\n",
    "\n",
    "fig = px.histogram(\n",
    "    missing_score[target_file],  # 最初のファイルのデータを使用\n",
    "    x=\"平均欠損率\",\n",
    "    nbins=50,\n",
    "    title=\"全企業の欠損率分布\"+files[0],\n",
    "    labels={\"平均欠損率\": \"平均欠損率\"}\n",
    ")\n",
    "#fig.show()\n",
    "# 特定範囲の欠損率を持つコードを抽出\n",
    "threshold_low = 0.215\n",
    "threshold_high= 0.225\n",
    "filtered_codes = missing_score[target_file][\n",
    "    (missing_score[target_file][\"平均欠損率\"] >= threshold_low) &\n",
    "    (missing_score[target_file][\"平均欠損率\"] < threshold_high)\n",
    "]\n",
    "#display(filtered_codes)\n",
    "# 列別欠損率\n",
    "df_by_code = all_df[target_file].set_index(\"コード\") # 企業コードを index にする\n",
    "codes = filtered_codes[\"コード\"].tolist() # 企業コードをリスト化\n",
    "subset = df_by_code.loc[df_by_code.index.isin(codes)] # 企業コードのデータ抽出\n",
    "#print(df_by_code)\n",
    "col_missing = subset.isnull().mean().sort_values(ascending=False) # 列別欠損率\n",
    "#display(col_missing)\n",
    "\n",
    "#年次別の欠損率推移確認\n",
    "df = all_df[target_file]\n",
    "year_all = (\n",
    "    df.groupby('年度')[['短期借入金', '長期借入金']].apply(lambda d: d.isnull().mean())\n",
    "    .apply(lambda d: d)\n",
    "    .reset_index()\n",
    ")\n",
    "# 欠損率の推移を可視化\n",
    "fig = px.line(\n",
    "    year_all,\n",
    "    x=\"年度\",\n",
    "    y=[\"短期借入金\", \"長期借入金\"],  # 複数列を同時に表示\n",
    "    markers=True,\n",
    "    title=\"各列の欠損率の推移\"\n",
    ")\n",
    "#fig.show()\n",
    "# 各企業の年次ごとの欠損率を計算し、\"常時欠損\" と \"変化あり\" を分類\n",
    "status = {}\n",
    "code_groups = subset.groupby(\"コード\")\n",
    "for code, g in code_groups:\n",
    "    rate_by_year = g[['短期借入金','長期借入金']].isnull().mean(axis=1)  # 年行ごとの欠損率\n",
    "    if rate_by_year.nunique() == 1 and rate_by_year.iloc[0] == 1.0:\n",
    "        status[code] = 'always_missing'\n",
    "    else:\n",
    "        status[code] = 'variable'\n",
    "pd.Series(status).value_counts()\n",
    "# variable の一部を表示して具体的な年次パターンを確認\n",
    "#for code, st in list(status.items())[:100]:\n",
    "    #if st == 'variable':\n",
    "        #print(code)\n",
    "        #display(code_groups.get_group(code)[['年度','短期借入金','長期借入金']].head(20))\n",
    "# 業種に偏りがあるか確認\n",
    "codes = filtered_codes[\"コード\"].tolist()\n",
    "p = os.path.join(base_path, files_reference[0])\n",
    "df = pd.read_csv(p,header=0,na_values=[])\n",
    "# 全体データ\n",
    "df_all = df.copy()\n",
    "df_all[\"区分\"] = \"全体\"\n",
    "# subsetデータ\n",
    "df_sub = df[df[\"コード\"].isin(codes)].copy()\n",
    "df_sub[\"区分\"] = \"抽出subset\"\n",
    "# 結合\n",
    "df_combined = pd.concat([df_all, df_sub])\n",
    "# Plotly Expressで可視化\n",
    "fig = px.histogram(\n",
    "    df_combined,\n",
    "    x=\"33業種区分\",\n",
    "    color=\"区分\",\n",
    "    barmode=\"group\",\n",
    "    histnorm=\"percent\",  # ← 割合表示\n",
    "    title=\"33業種区分別の構成比比較（全体 vs 抽出subset）\"\n",
    ")\n",
    "#fig.show()\n",
    "\n",
    "# # 時価総額に偏りがあるか確認\n",
    "# 時価総額の推定モデル：推定時価総額 = (PER * EPS) * (自己資本 / BPS) * (ROE / 10 + 営業CFマージン)\n",
    "# 4つのファイルを結合\n",
    "df_combined = pd.DataFrame()\n",
    "for filename in files:\n",
    "    df=all_df[filename]\n",
    "    df_combined = pd.concat([df_combined, df], axis=0)\n",
    "#display(df_combined)\n",
    "df = df_combined[[\"コード\",\"年度\",\"純利益\",\"EPS\",\"株主資本\",\"BPS\",\"ROE\",\"営業CFマージン\"]].copy()\n",
    "def combine_nonnull(series):\n",
    "    #そのグループ内で最初に非NaNの値を返す\n",
    "    return series.dropna().iloc[0] if series.notna().any() else np.nan\n",
    "\n",
    "# 「コード」「年度」でグループ化して統合\n",
    "df_merged = (\n",
    "    df.groupby([\"コード\", \"年度\"], as_index=False)\n",
    "      .agg(combine_nonnull)\n",
    "      .sort_values([\"コード\", \"年度\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "#display(df_merged.head(1000))\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(settings[\"data_path\"], settings[\"files_reference\"][0])\n",
    "df = pd.read_csv(p,header=0,na_values=[])\n",
    "all = df[\"コード\"].tolist()\n",
    "set_all = set(all)\n",
    "display(len(all))\n",
    "data = all_df[settings[\"files\"][0]][\"コード\"].unique().tolist()\n",
    "set_data = set(data)\n",
    "display(len(data))\n",
    "common = set_all & set_data\n",
    "only_a = list(set_all - set_data)\n",
    "only_b = list(set_data - set_all)\n",
    "display(len(common))\n",
    "display(only_a)\n",
    "display(only_b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
